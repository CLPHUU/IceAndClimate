{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31f626-2c3b-4010-b986-cb20f61db158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "rho   =  917.      # kg/m3\n",
    "g     =    9.80665 # m/s2\n",
    "fd    =    1.9E-24 # # pa-3 s-1 # this value and dimension is only correct for n=3\n",
    "fs    =    5.7E-20 # # pa-3 m2 s-1 # this value and dimension is only correct for n=3\n",
    "\n",
    "\n",
    "# this ELA list is not quite systematic, so make it systematic!\n",
    "# elalist = np.array([1800.])  # m , 1750., 1700., 1500., 2200., 1900., 1800.,\n",
    "# elayear = np.array([ 500], dtype=int)  # years    ,    100,   100,   150,    10,   100,   100\n",
    "\n",
    "cd    = 2/5*(rho**3)*(g**3)*fd  # <<< this must be adjused according to your discretisation -- Done\n",
    "cs    = (rho**3)*(g**3)*fs  # <<< this must be adjused according to your discretisation -- Done\n",
    "\n",
    "\n",
    "def get_bedrock(xaxis,slope=0.08):\n",
    "    '''\n",
    "    Function to get bedrock. \n",
    "    IN: \n",
    "    xaxis = array\n",
    "    slope = slope of underground, scalar\n",
    "    OUT:\n",
    "    bedrock profile\n",
    "    '''\n",
    "    # here you put in your own equation that defines the bedrock\n",
    "    bedrock = 2000. - xaxis*slope\n",
    "    return bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0599243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def icemodel(elalist,elayear,totL=20000,dx=100,ntpy=200,ZeroFluxBoundary=True,FluxAtPoints=True,ndyfigure=5,dbdh=0.007, maxb=2, initial_state=None, savename=None):\n",
    "    StopWhenOutOfDomain = True  \n",
    "    # Start calculations\n",
    "    # constants that rely on input\n",
    "\n",
    "    if dx == 50:\n",
    "        ntpy = ntpy*8\n",
    "\n",
    "    if initial_state is None:\n",
    "        nx    = int(totL/dx)\n",
    "        dx    = totL/nx       # redefine, as it     \n",
    "        xaxis = np.linspace(0,totL,nx,False) + dx*0.5\n",
    "        xhaxs = np.linspace(dx,totL,nx-1,False) / 1000.\n",
    "\n",
    "        bedrock = get_bedrock(xaxis)\n",
    "\n",
    "        dt    = 365.*86400./ntpy # in seconds!\n",
    "        \n",
    "        hice   = np.zeros(nx)    # ice thickness\n",
    "        dhdx   = np.zeros(nx)    # the local gradient of h\n",
    "        fluxd  = np.zeros(nx+2)  # this will be the flux per second!!!!\n",
    "        fluxs  = np.zeros(nx+2)  # this will be the flux per second!!!!\n",
    "        dhdtif = np.zeros(nx)    # change in ice thickness due to the ice flux, per second\n",
    "        smb    = np.zeros(nx)\n",
    "\n",
    "        # preparations for the ela-selection\n",
    "        # elaswch is a list of time steps on which a new ela value should be used.\n",
    "        nyear    = int(np.sum(elayear))\n",
    "        nela     = np.size(elalist)\n",
    "    \n",
    "    else:\n",
    "        nx    = int(totL/dx)\n",
    "        assert nx == initial_state['nx'], 'nx input and initial state should match!'\n",
    "        assert ntpy == initial_state['ntpy'], 'ntpy input and initial state should match!'\n",
    "        dx    = totL/nx\n",
    "        xaxis = np.linspace(0,totL,nx,False) + dx*0.5\n",
    "        xhaxs = np.linspace(dx, totL, nx-1, False) / 1000.\n",
    "\n",
    "        bedrock = get_bedrock(xaxis)\n",
    "        \n",
    "        dt = 365.*86400./ntpy # in seconds!\n",
    "        \n",
    "        hice   = initial_state['hice']    # ice thickness\n",
    "        dhdx   = initial_state['dhdx']    # the local gradient of h\n",
    "        fluxd  = initial_state['fluxd']  # this will be the flux per second!!!!\n",
    "        fluxs  = initial_state['fluxs']  # this will be the flux per second!!!!\n",
    "        dhdtif = initial_state['dhdtif']    # change in ice thickness due to the ice flux, per second\n",
    "        smb    = initial_state['smb'] # TODO: potentially force to zero?\n",
    "\n",
    "        # preparations for the ela-selection\n",
    "        # elaswch is a list of time steps on which a new ela value should be used.\n",
    "        nyear    = int(np.sum(elayear))\n",
    "        nela     = np.size(elalist)\n",
    "\n",
    "\n",
    "    assert nela == np.size(elayear), \"the arrays of elalist and elayear does not have the same length!\" \n",
    "    elaswch = np.zeros(nela)\n",
    "    for i in range(0,nela-1):\n",
    "        elaswch[i+1] = elaswch[i] + (elayear[i]*ntpy)\n",
    "    ela     = elalist[0]\n",
    "        \n",
    "\n",
    "    # preparations for the animation\n",
    "    nframes  = nyear//ndyfigure + 1\n",
    "    hsurfmem = np.zeros([nx,nframes])\n",
    "    smbmem   = np.zeros([nx,nframes])\n",
    "    ifdmem   = np.zeros([nx,nframes])\n",
    "    fldmem   = np.zeros([nx-1,nframes])\n",
    "    flsmem   = np.zeros([nx-1,nframes])\n",
    "    iframes  = 0\n",
    "\n",
    "    # preparations for response time calculations\n",
    "    lengthmem = np.zeros(nyear+1)\n",
    "    volumemem = np.zeros(nyear+1)\n",
    "    elamemory = np.zeros(nyear+1)\n",
    "    yearlist  = np.arange(nyear+1)\n",
    "    \n",
    "    # (re)set initial values so that the accumulation area has glacier right away.\n",
    "    hice = np.where(bedrock>ela, np.where(hice<0.11, 0.11, hice), hice)\n",
    "    \n",
    "    lengthmem[0] = np.sum(np.where(hice>0.1, dx, 0.))\n",
    "    volumemem[0] = np.sum(hice)*dx\n",
    "    elamemory[0] = ela\n",
    "\n",
    "\n",
    "    #0-----------------------------------------------------------------------------\n",
    "    print(\"Run model for {0:3d} years\".format(nyear))\n",
    "\n",
    "    for it in range(1, ntpy*nyear+1):\n",
    "        h = hice + bedrock\n",
    "        if FluxAtPoints:\n",
    "            dhdx[1:-1] = (h[2:]-h[:-2])/(2*dx)\n",
    "\n",
    "            # the following equations needs to be adjusted according to your discretisation\n",
    "            # note that flux[1] is at the point 0\n",
    "            fluxd[1:-1] = cd * (dhdx)**3 * (hice)**5  \n",
    "            fluxs[1:-1] = cs * (dhdx)**3 * (hice)**3\n",
    "\n",
    "            # derive flux convergence\n",
    "            dhdtif[:]  = (fluxd[2:]-fluxd[:-2]+fluxs[2:]-fluxs[:-2])/(2*dx)\n",
    "        else:\n",
    "            # the following equations needs to be adjusted according to your discretisation\n",
    "            dhdx[:-1]  = ((h[1:]-h[:-1])/dx) # so 0 is at 1/2 actually\n",
    "            # note that flux[1] is at the point 1/2\n",
    "            fluxd[1:-2] = cd * dhdx[:-1]**3 * ( ((hice[1:]**5)+(hice[:-1])**5) * 0.5 )\n",
    "            fluxs[1:-2] = cs * dhdx[:-1]**3 * ( ((hice[1:]**3)+(hice[:-1])**3) * 0.5 )\n",
    "\n",
    "            # derive flux convergence\n",
    "            dhdtif[:]  = (fluxd[1:-1]-fluxd[:-2] + fluxs[1:-1]-fluxs[:-2])/dx\n",
    "\n",
    "        # calculate smb (per year)\n",
    "        # first update ela (once a year)\n",
    "        if it%ntpy == 1:\n",
    "            # lists the elements of elaswch that are equal or smaller than it\n",
    "            [ielanow] = np.nonzero(elaswch<=it) \n",
    "            # the last one is the current ela\n",
    "            ela       = elalist[ielanow[-1]]   \n",
    "    \n",
    "        smb[:] = (h-ela)*dbdh\n",
    "        smb[:] = np.where(smb>maxb, maxb, smb) \n",
    "        \n",
    "        \n",
    "        \n",
    "        hice   += smb/ntpy + dt*dhdtif\n",
    "        hice[:] = np.where(hice<0., 0., hice) # remove negative ice thicknesses\n",
    "\n",
    "        if ZeroFluxBoundary == False:\n",
    "            hice[0] = hice[-1] = 0.\n",
    "\n",
    "        if it%ntpy == 0:\n",
    "            if np.any(np.isnan(hice)):\n",
    "                print('Values got NaN!')\n",
    "                break\n",
    "            iy = it//ntpy\n",
    "            lengthmem[iy] = np.sum(np.where(hice>0.1, dx, 0.))\n",
    "            volumemem[iy] = np.sum(hice)*dx\n",
    "            elamemory[iy] = ela\n",
    "\n",
    "        if it%(ndyfigure*ntpy) == 0:\n",
    "            iframes            += 1\n",
    "            hsurfmem[:,iframes] = hice + bedrock\n",
    "            smbmem[:,iframes]   = smb\n",
    "            ifdmem[:,iframes]   = dhdtif[:]*365.*86400.\n",
    "            fldmem[:,iframes]   = -fluxd[1:-2]*365.*86400.\n",
    "            flsmem[:,iframes]   = -fluxs[1:-2]*365.*86400.\n",
    "            if StopWhenOutOfDomain:\n",
    "                if hice[-1]>1.:\n",
    "                    print(\"Ice at end of domain!\")\n",
    "                    break\n",
    "                    \n",
    "#         runs = 0\n",
    "#         if it%(ntpy*ndyfigure) == 0:\n",
    "#             runs +=1\n",
    "#             if balance(smb[:runs]):\n",
    "#                 print(it)\n",
    "#                 break\n",
    "\n",
    "    #------------------------------------------------------------------------------        \n",
    "    # at this point, the simulation is completed.        \n",
    "    # the following is needed to make the animation        \n",
    "    fig  = plt.figure()\n",
    "    ax1  = fig.add_subplot(311, autoscale_on=False, xlim=(0,totL/1000.), \\\n",
    "                          ylim=(np.min(bedrock),np.max(hsurfmem)+10.))\n",
    "    ax1.set_ylabel('meter')\n",
    "    ax1.set_xlabel('km')\n",
    "    mina2 = min(np.min(smbmem),np.min(ifdmem))\n",
    "    maxa2 = max(np.max(smbmem),np.max(ifdmem))\n",
    "    ax2   = fig.add_subplot(312, autoscale_on=False, xlim=(0,totL/1000.), \\\n",
    "                          ylim=(mina2,maxa2))\n",
    "    ax2.set_ylabel('I dont know')\n",
    "    ax2.set_xlabel('km')\n",
    "    mina3 = min(np.min(fldmem),np.min(flsmem))\n",
    "    maxa3 = max(np.max(fldmem),np.max(flsmem))\n",
    "    ax3   = fig.add_subplot(313, autoscale_on=False, xlim=(0,totL/1000.), \\\n",
    "                          ylim=(mina3,maxa3))\n",
    "    ax3.set_xlabel('km')\n",
    "    ax3.set_ylabel('fluxd/fluxm')\n",
    "\n",
    "    # define the line types\n",
    "    bedrline, = ax1.plot([],[],'-', c='saddlebrown') \n",
    "    hsrfline, = ax1.plot([],[],'-', c='navy') #bedrline, +total surface \n",
    "    \n",
    "    time_template = 'time = %d y'\n",
    "    time_text = ax1.text(0.5, 0.92, '', transform=ax1.transAxes )\n",
    "    smbline,  = ax2.plot([],[],'-', c='navy') #surface mass balance\n",
    "    ifdline,  = ax2.plot([],[],'-', c='red') #ifd\n",
    "    fxdline,  = ax3.plot([],[],'-', c='navy') #flux\n",
    "    fxsline,  = ax3.plot([],[],'-', c='red') #flux\n",
    "\n",
    "    # initialize the animation\n",
    "    def init_anim():\n",
    "        '''function for initial animamtion'''\n",
    "        bedrline.set_data([], [])\n",
    "        hsrfline.set_data([], [])\n",
    "        time_text.set_text('')\n",
    "        smbline.set_data([], [])\n",
    "        ifdline.set_data([], [])\n",
    "        fxdline.set_data([], [])\n",
    "        fxsline.set_data([], [])\n",
    "\n",
    "        return bedrline, hsrfline, time_text, smbline, ifdline, fxdline, fxsline\n",
    "\n",
    "    # update the animation with data for saved frame #tf\n",
    "    def animate(tf):\n",
    "        bedrline.set_data(xaxis/1000., bedrock)\n",
    "        hsrfline.set_data(xaxis/1000., hsurfmem[:,tf]) \n",
    "        time_text.set_text(time_template % int(tf*ndyfigure))\n",
    "        smbline.set_data(xaxis/1000.,  smbmem[:,tf])\n",
    "        ifdline.set_data(xaxis/1000.,  ifdmem[:,tf])\n",
    "        fxdline.set_data(xhaxs      ,  fldmem[:,tf])\n",
    "        fxsline.set_data(xhaxs      ,  flsmem[:,tf])\n",
    "        return bedrline, hsrfline, time_text, smbline, ifdline, fxdline, fxsline\n",
    "\n",
    "    # call and run animation\n",
    "    ani = animation.FuncAnimation(fig, animate, np.arange(iframes),\n",
    "             interval=25, blit=True, init_func=init_anim) \n",
    "    \n",
    "    writergif = animation.PillowWriter(fps=30)\n",
    "    \n",
    "    if savename is not None:\n",
    "        s = os.path.join('..', 'Plots', f'{savename}.gif')\n",
    "        ani.save(s, writer=writergif)\n",
    "        plt.close()\n",
    "    else:\n",
    "        s = os.path.join('..', 'Plots', 'temp.gif')\n",
    "        ani.save(s, writer=writergif)\n",
    "    \n",
    "    # SAVING PYTHON MOVIES IS PLATFORM DEPENDEND.     \n",
    "\n",
    "    \n",
    "    #------------------------------------------------------------------------------ \n",
    "    # postprocessing\n",
    "\n",
    "    # The first ela value is excluded from the analysis as that has the spin-up\n",
    "    # Here, the length is used for the responsetime. One could also take the mass. \n",
    "    #  If desired, do not use lengthmem but volumemem.\n",
    "\n",
    "\n",
    "    fig2,ax2a = plt.subplots()\n",
    "    ax2a.plot(yearlist,lengthmem/1000. ,'k') #Black line \n",
    "    ax2a.set_xlabel('Model year [yr]')\n",
    "    ax2a.set_ylabel('Glacier length [km]')\n",
    "    ax2a.set_xlim([0, nyear])\n",
    "    lmima = [ np.min(lengthmem/1000.), np.max(lengthmem/1000.) ]\n",
    "\n",
    "    ax2b  = ax2a.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2b.plot(yearlist, elamemory, color=color) #Red line\n",
    "    ax2b.set_ylabel('ELA [m]', color=color)\n",
    "    ax2b.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    if savename is not None:\n",
    "        s = os.path.join('..', 'Plots', f'{savename}_len.png')\n",
    "        plt.savefig(s)\n",
    "        plt.close()\n",
    "    \n",
    "    returndict = {\n",
    "        'nx': nx,\n",
    "        'ntpy':ntpy,\n",
    "        'dx':dx,\n",
    "        'years':yearlist,\n",
    "        'Glacier Length':lengthmem,\n",
    "        'Glacier Volume':volumemem,\n",
    "        'Glacier ELA':elamemory,\n",
    "        'Glacier Height':hsurfmem,\n",
    "        'Surface Mass Balance': smbmem,\n",
    "        'ifd':ifdmem,\n",
    "        'fld':fldmem,\n",
    "        'fls':flsmem,\n",
    "        'hice':hice,\n",
    "        'dhdx':dhdx,\n",
    "        'fluxd':fluxd,\n",
    "        'fluxs':fluxs,\n",
    "        'dhdtif':dhdtif,\n",
    "        'smb':smb, #= smbmem[:, -1]\n",
    "        'Bedrock': bedrock,\n",
    "    }\n",
    "    return returndict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe07164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_response_time(diction, avgperiode=10, drift=None):\n",
    "    glacier_length = np.array(diction['Glacier Length'])\n",
    "    if drift is not None:\n",
    "         glacier_length = glacier_length - np.array(drift['Glacier Length'])\n",
    "    yearls = np.array(diction['years'])\n",
    "    end_len = np.mean(glacier_length[-avgperiode:])\n",
    "    start_len = glacier_length[0]\n",
    "    threshold = start_len + (end_len - start_len) * (1 - 1/np.e)\n",
    "    if glacier_length[0] < glacier_length[-1]: # glacier grows\n",
    "        response_idx = np.argmax(glacier_length > threshold)\n",
    "    else: # glacier shrinks\n",
    "        response_idx = np.argmax(glacier_length < threshold)\n",
    "    return yearls[response_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mass_change(diction, avgperiode=10, drift=None):\n",
    "    if drift is not None:\n",
    "        volume = np.array(diction['Glacier Volume']) - np.array(drift['Glacier Volume'])\n",
    "    else:\n",
    "        volume = np.array(diction['Glacier Volume']) \n",
    "    mass_begin = volume[0] * rho\n",
    "    mass_end = np.mean(volume[-avgperiode:]) * rho\n",
    "    mass_change = mass_end - mass_begin\n",
    "    return mass_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57593def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_smb(diction, avgperiod=1):\n",
    "    '''calculate integrated surface mass balance at end of simulation'''\n",
    "    smb = diction['Surface Mass Balance']\n",
    "    glacier_len = diction['Glacier Length'][-1]\n",
    "    idx = int(glacier_len / diction['dx'])\n",
    "    smb_int = np.mean(smb[:idx, -avgperiod:])\n",
    "    return smb_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial states for different dx\n",
    "import pickle\n",
    "ela_initial_arr = [1600]\n",
    "elayear_initial_arr = [1000]\n",
    "dxs = [50 100, 150, 200, 250, 300, 350, 400, 450, 500, 1000, 1500, 2000]\n",
    "\n",
    "\n",
    "for dx in dxs: \n",
    "    for idx, (ela_initial, elayear_initial) in enumerate(zip(ela_initial_arr, elayear_initial_arr)):\n",
    "\n",
    "        name = f'initial_{ela_initial}m_{dx}m_{elayear_initial}a'\n",
    "        pklsave = os.path.join('..', 'Savestates', f'{name}.pkl')\n",
    "\n",
    "        inital_state = icemodel([ela_initial], [elayear_initial],dx=dx, FluxAtPoints=False, savename=name)\n",
    "        \n",
    "        with open(pklsave, 'wb') as f:\n",
    "            pickle.dump(inital_state, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2143bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial states for different ELA\n",
    "dx_initial = 100\n",
    "ela_initial_arr = [1600, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n",
    "elayear_initial_arr = [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]            \n",
    "for idx, (ela_initial, elayear_initial) in enumerate(zip(ela_initial_arr, elayear_initial_arr)):\n",
    "\n",
    "    name = f'initial_{ela_initial}m_{dx_initial}m_{elayear_initial}a'\n",
    "    pklsave = os.path.join('..', 'Savestates', f'{name}.pkl')\n",
    "\n",
    "    inital_state = icemodel([ela_initial], [elayear_initial],dx=dx_initial, FluxAtPoints=False, savename=name)\n",
    "    \n",
    "    with open(pklsave, 'wb') as f:\n",
    "        pickle.dump(inital_state, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_initial_state(ela_initial, dx_initial, elayear_initial):\n",
    "    initial_name = f'initial_{ela_initial}m_{dx_initial}m_{elayear_initial}a'\n",
    "    pklload = os.path.join('..', 'Savestates', f'{initial_name}.pkl')\n",
    "    with open(pklload, 'rb') as f:\n",
    "        loaded_initial = pickle.load(f)\n",
    "    return loaded_initial, initial_name\n",
    "\n",
    "def run_model(ela, elayear, dx, initial_state, name_suffix):\n",
    "    name = f'{ela}m_{dx}m_{elayear}a-vs-{name_suffix}'\n",
    "    model = icemodel([ela], [elayear], dx=dx, FluxAtPoints=False, initial_state=initial_state, savename=name)\n",
    "    return model\n",
    "\n",
    "def compute_responses(ela_initial, dx, test_elayear, initial_state, ela2test, mass_change=False):\n",
    "    response_arr = []\n",
    "    dela_arr = []\n",
    "    mass_change_arr = []\n",
    "    smb_arr = []\n",
    "    initial_name = f'initial_{ela_initial}m_{dx}m_{test_elayear}a'\n",
    "    drift_name = f'drift_{ela_initial}m_{dx}m_{test_elayear}a'\n",
    "    model_drift = icemodel([ela_initial], [test_elayear], dx=dx, FluxAtPoints=False, initial_state=initial_state, savename=drift_name)\n",
    "    for test_ela in ela2test:\n",
    "        model = run_model(test_ela, test_elayear, dx, initial_state, initial_name)\n",
    "        response_arr.append(compute_response_time(model, drift=model_drift))\n",
    "        mass_change_arr.append(compute_mass_change(model, drift=model_drift))\n",
    "        dela_arr.append(test_ela - ela_initial)\n",
    "        smb_arr.append(avg_smb(model))\n",
    "    if not mass_change:\n",
    "        return response_arr, dela_arr, smb_arr\n",
    "    else:\n",
    "        return response_arr, dela_arr, smb_arr, mass_change_arr\n",
    "\n",
    "ela_initial_arr = [1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n",
    "elayear_initial_arr = [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n",
    "ela2test = np.arange(1300, 2001, 100)\n",
    "all_response_times = []\n",
    "all_delas = []\n",
    "all_mass_changes = []\n",
    "all_avg_smbs = []\n",
    "dx_initial = 100\n",
    "\n",
    "for idx, (ela_initial, elayear_initial) in enumerate(zip(ela_initial_arr, elayear_initial_arr)):\n",
    "    loaded_initial, initial_name = load_initial_state(ela_initial, dx_initial, elayear_initial)\n",
    "    dx = 100 \n",
    "    test_elayear = 1000\n",
    "    response_arr, dela_arr, avg_smb_arr, mass_change_arr = compute_responses(ela_initial, dx, test_elayear, loaded_initial, ela2test, mass_change=True)\n",
    "    all_response_times.append(response_arr)\n",
    "    all_delas.append(dela_arr)\n",
    "    all_mass_changes.append(mass_change_arr)\n",
    "    all_avg_smbs.append(avg_smb_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "for idx, (rt, e) in enumerate(zip(all_response_times, all_delas)):\n",
    "    plt.scatter(e, np.array(all_avg_smbs[idx])/1.825*100, label=f'Initial ELA = {ela_initial_arr[idx]}', alpha=0.8, s=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('dELA [m]')\n",
    "    plt.ylabel('Average SMB [cm/day]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "for idx, (rt, e) in enumerate(zip(all_response_times, all_delas)):\n",
    "    # plt.scatter(e, rt, label=f'Initial ELA = {ela_initial_arr[idx]}')\n",
    "    plt.scatter(e, np.array(all_mass_changes[idx]) / 1e9, label=f'Initial ELA = {ela_initial_arr[idx]}', alpha=0.8, s=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('dELA [m]')\n",
    "    plt.ylabel('Mass Change [MT]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b4aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "for idx, (rt, e) in enumerate(zip(all_response_times, all_delas)):\n",
    "    plt.scatter(e, rt, label=f'Initial ELA = {ela_initial_arr[idx]}', alpha=0.8, s=15)\n",
    "    # plt.scatter(e, all_mass_changes[idx])\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('dELA [m]')\n",
    "    plt.ylabel('Response Time [years]')\n",
    "    # plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_different_dx(dx):\n",
    "    ela_initial_arr = [1600]\n",
    "    elayear_initial_arr = [1000]\n",
    "    ela2test = np.arange(1300, 2001, 100)\n",
    "    all_response_times = []\n",
    "    all_delas = []\n",
    "    all_mass_changes = []\n",
    "    all_avg_smbs = []\n",
    "    dx_initial = dx\n",
    "\n",
    "    for idx, (ela_initial, elayear_initial) in enumerate(zip(ela_initial_arr, elayear_initial_arr)):\n",
    "        loaded_initial, initial_name = load_initial_state(ela_initial, dx_initial, elayear_initial)\n",
    "        dx = dx  # or vary dx here in a nested loop or however you plan to do it\n",
    "        test_elayear = 1000\n",
    "        response_arr, dela_arr, avg_smb_arr, mass_change_arr = compute_responses(ela_initial, dx, test_elayear, loaded_initial, ela2test, mass_change=True)\n",
    "        all_response_times.append(response_arr)\n",
    "        all_delas.append(dela_arr)\n",
    "        all_mass_changes.append(mass_change_arr)\n",
    "        all_avg_smbs.append(avg_smb_arr)\n",
    "    \n",
    "    return all_response_times, all_delas, all_mass_changes, all_avg_smbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28795f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_values = [50,100,150,200,250,300,350,400,450,500]  \n",
    " \n",
    "dx_return_dict = {dx: run_different_dx(dx) for dx in dx_values}\n",
    "\n",
    "with open('dx_return_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(dx_return_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f564e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_values_new = [1000,1500,2000]  \n",
    "dx_return_dict_new = {dx: run_different_dx(dx) for dx in dx_values_new}\n",
    "\n",
    "with open('dx_return_dict_version_2.pickle', 'wb') as f:\n",
    "    pickle.dump(dx_return_dict_new, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "dEla = dx_return_dict[100][1]\n",
    "\n",
    "plt.scatter(dEla, dx_return_dict[50][0], marker='o', label='dx=50',alpha=.8,s=15)\n",
    "plt.scatter(dEla, dx_return_dict[100][0], marker='o', label='dx=100',alpha=.8,s=15)\n",
    "plt.scatter(dEla, dx_return_dict[200][0], marker='o', label='dx=200',alpha=.8,s=15)\n",
    "plt.scatter(dEla, dx_return_dict[500][0], marker='o', label='dx=500',alpha=.8,s=15)\n",
    "\n",
    "for key, value in dx_return_dict_new.items():\n",
    "    plt.scatter(dEla[0], value[0][0] , label=f'dx={key}', marker='o',alpha=.8,s=15)\n",
    "plt.xlabel('dEla[m]')\n",
    "plt.ylabel('Response Time [years]')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad41fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "dEla = dx_return_dict[100][1]\n",
    "# Assuming `results_dict` is your dictionary of results\n",
    "for key, value in dx_return_dict.items():\n",
    "    plt.scatter(dEla[0], np.array(value[2][0])/1e9 , label=f'dx={key}', marker='.')\n",
    "for key, value in dx_return_dict_new.items():\n",
    "    plt.scatter(dEla[0], np.array(value[2][0])/1e9 , label=f'dx={key}', marker='.')\n",
    "\n",
    "plt.xlabel('dEla[m]')\n",
    "plt.ylabel('Mass Change [MT]')\n",
    "# plt.title('Response Time for different dx')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
